# ğŸ“š Simple RAG Chatbot with Gemini 2.5 and LangChain

This project is a simple **Retrieval-Augmented Generation (RAG) chatbot** built using:

- ğŸ§  **Google Gemini 2.5 Flash**
- ğŸ§± **LangChain for chaining + document loading**
- ğŸ“„ **Chroma for vector storage**
- ğŸ” **PDFMiner for parsing PDFs**

It allows users to ask questions about a PDF and get accurate, source-grounded answers. Ideal for use cases like analyzing novels, academic papers, or course notes. 

This project currently loads and processes one PDF file a book i read recently "The Death of Vivek Oji" for simplicity and experimentation purposes.
Did this as part of a learning project to understand how Retrieval-Augmented Generation (RAG) actually works with LangChain and Gemini. This made it easier for me to test, debug, and build foundational knowledge.

---

## âœ¨ Features

- âœ… Loads a PDF and splits it into retrievable chunks
- âœ… Uses Gemini embeddings and language model for Q&A
- âœ… Returns answer + source context for transparency
- âœ… Runs locally from your terminal
- âœ… Easily extendable for multiple PDFs or API deployment

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ the_death_of_vivek_oji.pdf    # Your input PDF
â”œâ”€â”€ rag.py                        # Main Python file
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ .env                          # Your API keys
